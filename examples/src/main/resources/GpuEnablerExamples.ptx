//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19856038
// Cuda compilation tools, release 7.5, V7.5.17
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_35
.address_size 64

	// .weak	cudaMalloc
.extern .func __assertfail
(
	.param .b64 __assertfail_param_0,
	.param .b64 __assertfail_param_1,
	.param .b32 __assertfail_param_2,
	.param .b64 __assertfail_param_3,
	.param .b64 __assertfail_param_4
)
;
.global .align 1 .b8 __T20[44] = {118, 111, 105, 100, 32, 115, 117, 109, 40, 105, 110, 116, 32, 42, 44, 32, 105, 110, 116, 32, 42, 44, 32, 105, 110, 116, 32, 42, 44, 32, 105, 110, 116, 32, 42, 44, 32, 105, 110, 116, 32, 42, 41, 0};
.global .align 1 .b8 $str[31] = {106, 117, 109, 112, 32, 61, 61, 32, 98, 108, 111, 99, 107, 68, 105, 109, 46, 120, 32, 42, 32, 103, 114, 105, 100, 68, 105, 109, 46, 120, 0};
.global .align 1 .b8 $str1[22] = {71, 112, 117, 69, 110, 97, 98, 108, 101, 114, 69, 120, 97, 109, 112, 108, 101, 115, 46, 99, 117, 0};

.weak .func  (.param .b32 func_retval0) cudaMalloc(
	.param .b64 cudaMalloc_param_0,
	.param .b64 cudaMalloc_param_1
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaFuncGetAttributes
.weak .func  (.param .b32 func_retval0) cudaFuncGetAttributes(
	.param .b64 cudaFuncGetAttributes_param_0,
	.param .b64 cudaFuncGetAttributes_param_1
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaDeviceGetAttribute
.weak .func  (.param .b32 func_retval0) cudaDeviceGetAttribute(
	.param .b64 cudaDeviceGetAttribute_param_0,
	.param .b32 cudaDeviceGetAttribute_param_1,
	.param .b32 cudaDeviceGetAttribute_param_2
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaGetDevice
.weak .func  (.param .b32 func_retval0) cudaGetDevice(
	.param .b64 cudaGetDevice_param_0
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessor
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessor(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_3
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_3,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_4
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	multiplyBy2
.visible .entry multiplyBy2(
	.param .u64 multiplyBy2_param_0,
	.param .u64 multiplyBy2_param_1,
	.param .u64 multiplyBy2_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<10>;


	ld.param.u64 	%rd3, [multiplyBy2_param_0];
	ld.param.u64 	%rd1, [multiplyBy2_param_1];
	ld.param.u64 	%rd2, [multiplyBy2_param_2];
	cvta.to.global.u64 	%rd4, %rd3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r1, %r2, %r3, %r4;
	ld.global.u32 	%r5, [%rd4];
	setp.ge.s32	%p1, %r1, %r5;
	@%p1 bra 	BB6_2;

	cvta.to.global.u64 	%rd5, %rd1;
	mul.wide.s32 	%rd6, %r1, 4;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.u32 	%r6, [%rd7];
	shl.b32 	%r7, %r6, 1;
	cvta.to.global.u64 	%rd8, %rd2;
	add.s64 	%rd9, %rd8, %rd6;
	st.global.u32 	[%rd9], %r7;

BB6_2:
	ret;
}

	// .globl	sum
.visible .entry sum(
	.param .u64 sum_param_0,
	.param .u64 sum_param_1,
	.param .u64 sum_param_2,
	.param .u64 sum_param_3,
	.param .u64 sum_param_4
)
{
	.reg .pred 	%p<10>;
	.reg .b32 	%r<28>;
	.reg .b64 	%rd<43>;


	ld.param.u64 	%rd16, [sum_param_0];
	ld.param.u64 	%rd17, [sum_param_1];
	ld.param.u64 	%rd15, [sum_param_2];
	ld.param.u64 	%rd18, [sum_param_3];
	cvta.to.global.u64 	%rd39, %rd17;
	cvta.to.global.u64 	%rd2, %rd16;
	mov.u32 	%r1, %tid.x;
	cvt.u64.u32	%rd19, %r1;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.wide.u32 	%rd20, %r3, %r2;
	add.s64 	%rd3, %rd20, %rd19;
	cvta.to.global.u64 	%rd21, %rd18;
	ld.global.u32 	%r13, [%rd21];
	setp.eq.s32	%p1, %r13, 0;
	@%p1 bra 	BB7_5;

	setp.ne.s64	%p2, %rd3, 0;
	@%p2 bra 	BB7_12;

	ld.global.s32 	%rd23, [%rd2];
	setp.lt.s64	%p3, %rd23, 16384;
	selp.b64	%rd4, %rd23, 16384, %p3;
	mov.u32 	%r24, 0;
	mov.u32 	%r25, %r24;
	mov.u64 	%rd40, 0;
	setp.lt.s64	%p4, %rd4, 1;
	@%p4 bra 	BB7_4;

BB7_3:
	ld.global.u32 	%r16, [%rd39];
	add.s32 	%r25, %r16, %r25;
	add.s64 	%rd39, %rd39, 4;
	add.s64 	%rd40, %rd40, 1;
	setp.lt.s64	%p5, %rd40, %rd4;
	mov.u32 	%r24, %r25;
	@%p5 bra 	BB7_3;

BB7_4:
	cvta.to.global.u64 	%rd24, %rd15;
	st.global.u32 	[%rd24], %r24;
	bra.uni 	BB7_12;

BB7_5:
	ld.global.u32 	%r26, [%rd2];
	cvt.s64.s32	%rd25, %r26;
	setp.ge.s64	%p6, %rd3, %rd25;
	@%p6 bra 	BB7_12;

	mov.u32 	%r17, %nctaid.x;
	mul.lo.s32 	%r18, %r17, %r3;
	setp.eq.s32	%p7, %r18, 16384;
	@%p7 bra 	BB7_8;

	mov.u64 	%rd26, $str;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str1;
	cvta.global.u64 	%rd29, %rd28;
	mov.u64 	%rd30, __T20;
	cvta.global.u64 	%rd31, %rd30;
	mov.u32 	%r19, 21;
	mov.u64 	%rd32, 1;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32	[param2+0], %r19;
	.param .b64 param3;
	st.param.b64	[param3+0], %rd31;
	.param .b64 param4;
	st.param.b64	[param4+0], %rd32;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	
	//{
	}// Callseq End 0
	ld.global.u32 	%r26, [%rd2];

BB7_8:
	cvt.s64.s32	%rd9, %r26;
	mov.u32 	%r27, 0;
	setp.ge.s64	%p8, %rd3, %rd9;
	@%p8 bra 	BB7_11;

	add.s64 	%rd35, %rd20, %rd19;
	shl.b64 	%rd36, %rd35, 2;
	add.s64 	%rd41, %rd39, %rd36;
	mov.u32 	%r27, 0;
	mov.u64 	%rd42, %rd3;

BB7_10:
	mov.u64 	%rd12, %rd42;
	ld.global.u32 	%r22, [%rd41];
	add.s32 	%r27, %r22, %r27;
	add.s64 	%rd41, %rd41, 65536;
	add.s64 	%rd14, %rd12, 16384;
	setp.lt.s64	%p9, %rd14, %rd9;
	mov.u64 	%rd42, %rd14;
	@%p9 bra 	BB7_10;

BB7_11:
	shl.b64 	%rd37, %rd3, 2;
	add.s64 	%rd38, %rd39, %rd37;
	st.global.u32 	[%rd38], %r27;

BB7_12:
	ret;
}

	// .globl	sum1
.visible .entry sum1(
	.param .u64 sum1_param_0,
	.param .u64 sum1_param_1,
	.param .u64 sum1_param_2
)
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd7, [sum1_param_0];
	ld.param.u64 	%rd8, [sum1_param_1];
	ld.param.u64 	%rd9, [sum1_param_2];
	mov.u32 	%r5, %tid.x;
	cvt.u64.u32	%rd10, %r5;
	mov.u32 	%r6, %ctaid.x;
	cvt.u64.u32	%rd11, %r6;
	mov.u32 	%r7, %ntid.x;
	cvt.u64.u32	%rd12, %r7;
	neg.s64 	%rd13, %rd11;
	mul.lo.s64 	%rd14, %rd12, %rd13;
	setp.ne.s64	%p1, %rd10, %rd14;
	@%p1 bra 	BB8_5;

	cvta.to.global.u64 	%rd15, %rd7;
	ld.global.u32 	%r1, [%rd15];
	mov.u32 	%r11, 0;
	setp.lt.s32	%p2, %r1, 1;
	@%p2 bra 	BB8_4;

	cvta.to.global.u64 	%rd18, %rd8;
	cvt.s64.s32	%rd2, %r1;
	mov.u32 	%r11, 0;
	mov.u64 	%rd19, 0;

BB8_3:
	ld.global.u32 	%r10, [%rd18];
	add.s32 	%r11, %r10, %r11;
	add.s64 	%rd18, %rd18, 4;
	add.s64 	%rd19, %rd19, 1;
	setp.lt.s64	%p3, %rd19, %rd2;
	@%p3 bra 	BB8_3;

BB8_4:
	cvta.to.global.u64 	%rd17, %rd9;
	st.global.u32 	[%rd17], %r11;

BB8_5:
	ret;
}


